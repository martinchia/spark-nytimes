{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('stopwords.txt','r')\n",
    "stop = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "global stopwords\n",
    "stopwords = {}\n",
    "for word in stop:\n",
    "    stopwords[word] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load text files from multiple folders as an rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = sc.textFile(\"data/Sports,data/Politics,data/Science,data/Business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWords(word):\n",
    "    stemmer = PorterStemmer()\n",
    "    try:\n",
    "        if stopwords[word]:\n",
    "            return False #this word should be abandoned when return true\n",
    "    except KeyError:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitwords(line):\n",
    "    words = line.split(\" \")\n",
    "    returnwords = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for word in words:\n",
    "        if(re.match('http.*',word)):\n",
    "                continue\n",
    "        word = ''.join(re.findall(r'[0-9a-zA-Z]*', word))\n",
    "        if(len(word)>10):\n",
    "            continue\n",
    "        if(word.isdigit()):\n",
    "            continue\n",
    "        word = word.lower()\n",
    "        word = stemmer.stem(word)\n",
    "        returnwords.append(word)\n",
    "    return returnwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(word):\n",
    "    return (word,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the word count for all articals and extract the top 1000 words as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = text_file.flatMap(splitwords).filter(stopWords).map(mapper).reduceByKey(lambda a, b: a + b).\\\n",
    "takeOrdered(1000, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "global feature\n",
    "feature = {}\n",
    "for i in range(len(counts)):\n",
    "    feature[counts[i][0]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textdf(list_, folder,label):\n",
    "    t = []\n",
    "    for i in range(len(list_)):\n",
    "        filename = \"data/\"+folder + \"/\" + list_[i]\n",
    "        f = open(filename,\"r\",encoding = \"utf-8\")\n",
    "        t.append(f.read())\n",
    "    df = pd.DataFrame({\"content\":t, \"label\":[label]*len(t)})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Politics', 'Sports', 'Science', 'Business']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get labels from the folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_list[0]\n",
    "file_list = os.listdir(f\"data/{label}\")\n",
    "Politics_df = textdf(file_list,label,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_list[1]\n",
    "file_list = os.listdir(f\"data/{label}\")\n",
    "Sports_df = textdf(file_list,label,1)\n",
    "\n",
    "label = label_list[2]\n",
    "file_list = os.listdir(f\"data/{label}\")\n",
    "Science_df = textdf(file_list,label,2)\n",
    "\n",
    "label = label_list[3]\n",
    "file_list = os.listdir(f\"data/{label}\")\n",
    "Business_df = textdf(file_list,label,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly seperate data into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf = Science_df.append([Business_df, Politics_df, Sports_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf = resultdf.reindex(np.random.permutation(resultdf.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty = round(len(resultdf)/5)\n",
    "train_set = resultdf[0:(twenty*3)]\n",
    "test_set = resultdf[(twenty*3):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform pandas dataframe into spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sqlCtx.createDataFrame(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = sqlCtx.createDataFrame(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for words in one artical, once a word in feature appears, the feature vector +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ab(line):\n",
    "    f = [0]*1000\n",
    "    text = line[0]\n",
    "    label = line[1]\n",
    "    stemmer = PorterStemmer()\n",
    "    words = text.lower().split(\" \")\n",
    "    for i in words:\n",
    "        i = stemmer.stem(i)\n",
    "        try:\n",
    "            num = feature[i]\n",
    "            f[num] +=1 #or just = 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return LabeledPoint(label,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_train.rdd.map(feature_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LogisticRegressionWithLBFGS.train(train_data, iterations=100, numClasses=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning Accuracy = 98.38308457711443%\n"
     ]
    }
   ],
   "source": [
    "labelsAndPreds = train_data.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(train_data.count())\n",
    "print(\"trainning Accuracy = \" + str((1-trainErr)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df_test.rdd.map(feature_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy = 94.83830845771143%\n"
     ]
    }
   ],
   "source": [
    "labelsAndPreds_test = test_data.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "testErr = labelsAndPreds_test.filter(lambda lp: lp[0] != lp[1]).count() / float(test_data.count())\n",
    "print(\"testing Accuracy = \" + str((1-testErr)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes.train(train_data, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning Accuracy = 96.41376451077943%\n"
     ]
    }
   ],
   "source": [
    "labelsAndPreds_bayes = train_data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds_bayes.filter(lambda lp: lp[0] != lp[1]).count() / float(train_data.count())\n",
    "print(\"trainning Accuracy = \" + str((1-trainErr)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy = 96.23756218905473%\n"
     ]
    }
   ],
   "source": [
    "labelsAndPreds_test_bayes = test_data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "testErr = labelsAndPreds_test_bayes.filter(lambda lp: lp[0] != lp[1]).count() / float(test_data.count())\n",
    "print(\"testing Accuracy = \" + str((1-testErr)*100)+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
